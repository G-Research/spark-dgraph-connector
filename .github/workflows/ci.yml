name: CI

on: [push, pull_request_target]

jobs:
  build-and-test:
    name: Build and Test (Dgraph ${{ matrix.dgraph-version }} and Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    if: >
      github.event_name == 'push' ||
      github.event_name == 'pull_request_target' && github.event.pull_request.head.repo.full_name != github.repository

    strategy:
      fail-fast: false
      matrix:
        spark-version: [3.0.0]
        dgraph-version: [20.03.3]
        python-version: [3.6]
        include:
          - spark-version: '3.0.0'
            spark-compat-version: '3.0'

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    - name: Parametrize
      id: params
      run: |
        echo "::set-output name=artifact-id::$(grep --max-count=1 "<artifactId>.*</artifactId>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")"
        echo "::set-output name=version::$(grep --max-count=1 "<version>.*</version>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")"
        echo "::set-output name=home::$(cd ~; pwd)"
      shell: bash

    - name: Cache Pip packages
      uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-packages-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-packages-${{ matrix.python-version }}-

    - name: Cache Maven packages
      uses: actions/cache@v2
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-mvn-packages-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-mvn-packages-

    - name: Cache Spark Binaries
      uses: actions/cache@v2
      with:
        path: ~/spark
        key: ${{ runner.os }}-spark-binaries-${{ matrix.spark-version }}

    - name: Setup JDK 1.8
      uses: actions/setup-java@v1
      with:
        java-version: 1.8

    - name: Setup Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r python/requirements.txt
        pip install pytest

    - name: Build and Test
      env:
        DGRAPH_TEST_CLUSTER_VERSION: ${{ matrix.dgraph-version }}
      run: mvn --batch-mode test

    - name: PyTest
      env:
        DGRAPH_TEST_CLUSTER_VERSION: ${{ matrix.dgraph-version }}
        PYTHONPATH: python:python/test
      run: |
        mkdir -p target/surefire-reports
        python -m pytest python/test --junit-xml target/surefire-reports/pytest.xml

    - name: Generate Unit Test Report
      if: failure()
      run: mvn --batch-mode surefire-report:report-only

    - name: Upload Unit Test Results
      if: always()
      uses: actions/upload-artifact@v2
      with:
        name: Unit Test Results (Dgraph ${{ matrix.dgraph-version }} and Python ${{ matrix.python-version }})
        path: |
          target/surefire-reports/*.xml
          !target/surefire-reports/TEST-org.scalatest*.xml
          target/site/surefire-report.html

    - name: Setup Spark Binaries
      env:
        SPARK_PACKAGE: spark-${{ matrix.spark-version }}/spark-${{ matrix.spark-version }}-bin-hadoop2.7.tgz
      run: |
        if [[ ! -e "~/spark" ]]
        then
          wget --progress=dot:giga https://archive.apache.org/dist/spark/${SPARK_PACKAGE} -O - | tar -xzC "${{ runner.temp }}"
          archive=$(basename "${SPARK_PACKAGE}") bash -c "mv -v "${{ runner.temp }}/\${archive/%.tgz/}" ~/spark"
        fi
        ls -lah ~/spark
        ls -lah ~/spark/bin
      shell: bash

    - name: Prepare Integration Tests
      run: |
        mvn install -DskipTests
        cd examples/scala
        mvn package
      shell: bash

    - name: Integration Tests
      env:
        SPARK_HOME: ${{ steps.params.outputs.home }}/spark
        ARTIFACT_ID: ${{ steps.params.outputs.artifact-id }}
        VERSION: ${{ steps.params.outputs.version }}
      run: |
        ls -lahR "${{ runner.workspace }}"
        ${SPARK_HOME}/bin/spark-submit --packages uk.co.gresearch.spark:${ARTIFACT_ID}:${VERSION},graphframes:graphframes:0.8.0-spark${{ matrix.spark-compat-version }}-s_2.12 --class uk.co.gresearch.spark.dgraph.connector.example.ExampleApp examples/scala/target/spark-dgraph-connector-examples_*.jar
      shell: bash

  publish-test-results:
    name: "Publish Unit Tests Results"
    needs: build-and-test
    runs-on: ubuntu-latest
    if: success() || failure()

    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v2
        with:
          path: artifacts

      - name: Publish Unit Test Results
        uses: EnricoMi/publish-unit-test-result-action@master
        with:
          check_name: Unit Test Results
          github_token: ${{ secrets.GITHUB_TOKEN }}
          files: "artifacts/**/*.xml"
          log_level: DEBUG
