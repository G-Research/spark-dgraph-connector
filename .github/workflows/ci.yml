name: CI

on:
  push:
    branches:
      - 'main'
    tags:
      - '*'
  pull_request:
  workflow_dispatch:

jobs:
  event_file:
    name: "Event File"
    runs-on: ubuntu-latest
    steps:
      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: Event File
          path: ${{ github.event_path }}

  lint:
    name: "Linting"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cache Maven packages
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-mvn-lint-${{ hashFiles('pom.xml') }}

      - name: Setup JDK ${{ inputs.java-compat-version }}
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'zulu'

      - name: Check
        id: check
        run: |
          mvn --batch-mode spotless:check
        shell: bash

      - name: Changes
        if: failure() && steps.check.outcome == 'failure'
        run: |
          mvn --batch-mode spotless:apply
          git diff
        shell: bash

  download:
    name: "Spark"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # use spark versions from test-integration.yaml workflow
        include:
          - spark-version: '3.0.3'
            hadoop-version: '2.7'
          - spark-version: '3.1.3'
            hadoop-version: '2.7'
          - spark-version: '3.2.4'
            hadoop-version: '2.7'
          - spark-version: '3.3.4'
            hadoop-version: '3'
          - spark-version: '3.4.3'
            hadoop-version: '3'
          - spark-version: '3.5.3'
            hadoop-version: '3'
          - spark-version: '4.0.0-preview2'
            hadoop-version: '3'
    steps:
      - name: Cache Spark Binaries
        uses: actions/cache@v4
        with:
          path: ~/spark
          key: ${{ runner.os }}-spark-binaries-${{ inputs.spark-version }}-${{ inputs.scala-compat-version }}

      - name: Setup Spark Binaries
        env:
          SPARK_PACKAGE: spark-${{ inputs.spark-version }}/spark-${{ inputs.spark-version }}-bin-hadoop${{ inputs.hadoop-version }}.tgz
        run: |
          if [[ ! -e ~/spark ]]
          then
            wget --progress=dot:giga "https://www.apache.org/dyn/closer.lua/spark/${SPARK_PACKAGE}?action=download" -O - | tar -xzC "${{ runner.temp }}"
            archive=$(basename "${SPARK_PACKAGE}") bash -c "mv -v "${{ runner.temp }}/\${archive/%.tgz/}" ~/spark"
          fi
        shell: bash

      - name: Upload Spark Binaries
        uses: actions/upload-artifact@v4
        with:
          name: Spark-Binaries-${{ inputs.spark-version }}-${{ inputs.hadoop-version }}
          path: ~/spark

  build:
    name: "Build"
    uses: "./.github/workflows/build.yml"

  test-dgraph:
    name: "Test Dgraph"
    needs: build
    uses: "./.github/workflows/test-dgraph.yml"

  test-spark:
    name: "Test Spark (Dgraph ${{ matrix.dgraph-version }})"
    needs: build
    strategy:
      fail-fast: false
      matrix:
        include:
          - dgraph-version: "21.12.0"
          - dgraph-version: "22.0.2"
          - dgraph-version: "23.1.1"
          - dgraph-version: "24.0.2"
    uses: "./.github/workflows/test-spark.yml"
    with:
      dgraph-version: ${{ matrix.dgraph-version }}

  test-scala:
    name: "Test Scala (2.13)"
    needs: build
    uses: "./.github/workflows/test-scala.yml"
    with:
      # not running 4.0.0-preview2 here as it is tested in test-dgraph already
      matrix: |
        {
          "include": [
            {
              "spark-version": "3.2.4",
              "spark-compat-version": "3.2",
              "scala-compat-version": "2.13",
              "scala-version": "2.13.5",
              "java-version": "11",
              "dgraph-version": "24.0.2"
            },
            {
              "spark-version": "3.3.4",
              "spark-compat-version": "3.3",
              "scala-compat-version": "2.13",
              "scala-version": "2.13.8",
              "java-version": "11",
              "dgraph-version": "24.0.2"
            },
            {
              "spark-version": "3.4.3",
              "spark-compat-version": "3.4",
              "scala-compat-version": "2.13",
              "scala-version": "2.13.8",
              "java-version": "11",
              "dgraph-version": "24.0.2"
            },
            {
              "spark-version": "3.5.3",
              "spark-compat-version": "3.5",
              "scala-compat-version": "2.13",
              "scala-version": "2.13.8",
              "java-version": "11",
              "dgraph-version": "24.0.2"
            }
          ]
        }

  test-python:
    name: "Test Python"
    needs: [test-dgraph, test-spark]
    uses: "./.github/workflows/test-python.yml"

  test-integration:
    name: "Test Integration"
    needs: [test-dgraph, test-spark]
    uses: "./.github/workflows/test-integration.yml"

  delete_binaries:
    name: "Delete Binaries"
    runs-on: ubuntu-latest
    needs: [test-dgraph, test-spark, test-scala, test-python, test-integration]
    steps:
      - name: Delete Binaries Artifact
        uses: geekyeggo/delete-artifact@v5
        with:
          name: "Binaries-*"
