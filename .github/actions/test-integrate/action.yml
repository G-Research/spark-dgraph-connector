name: 'Test Integration'
author: 'EnricoMi'
description: 'A GitHub Action that tests spark-dgraph-connector integrating with Dgraph and Spark'

inputs:
  spark-version:
    description: Spark version, e.g. 3.4.0 or 3.4.0-SNAPSHOT
    required: true
  scala-version:
    description: Scala version, e.g. 2.12.15
    required: true
  spark-compat-version:
    description: Spark compatibility version, e.g. 3.4
    required: true
  scala-compat-version:
    description: Scala compatibility version, e.g. 2.12
    required: true
  java-version:
    description: Java version, e.g. 11
    required: true
  dgraph-version:
    description: Dgraph server version, e.g. 22.0.0
    required: true
  hadoop-version:
    description: Hadoop version, e.g. 2.7 or 2
    required: true

runs:
  using: 'composite'
  steps:
    - name: Set versions in pom.xml
      run: |
        ./set-version.sh ${{ inputs.spark-version }} ${{ inputs.scala-version }}
        git diff
      shell: bash

    - name: Fetch Binaries Artifact
      uses: actions/download-artifact@v4
      with:
        name: Binaries-${{ inputs.spark-compat-version }}-${{ inputs.scala-compat-version }}
        path: .

    - name: Cache Maven packages
      uses: actions/cache@v4
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-mvn-integrate-${{ inputs.spark-version }}-${{ inputs.scala-compat-version }}-${{ hashFiles('pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-mvn-integrate-${{ inputs.spark-version }}-${{ inputs.scala-compat-version }}-
          ${{ runner.os }}-mvn-build-${{ inputs.spark-version }}-${{ inputs.scala-compat-version }}-

    - name: Cache Spark Binaries
      uses: actions/cache@v4
      with:
        path: ~/spark
        key: ${{ runner.os }}-spark-binaries-${{ inputs.spark-version }}-${{ inputs.scala-compat-version }}

    - name: Setup JDK
      uses: actions/setup-java@v4
      with:
        java-version: ${{ inputs.java-version }}
        distribution: 'zulu'

    - name: Setup Spark Binaries
      env:
        SPARK_PACKAGE: spark-${{ inputs.spark-version }}/spark-${{ inputs.spark-version }}-bin-hadoop${{ inputs.hadoop-version }}.tgz
      run: |
        if [[ ! -e ~/spark ]]
        then
          wget --progress=dot:giga "https://www.apache.org/dyn/closer.lua/spark/${SPARK_PACKAGE}?action=download" -O - | tar -xzC "${{ runner.temp }}"
          archive=$(basename "${SPARK_PACKAGE}") bash -c "mv -v "${{ runner.temp }}/\${archive/%.tgz/}" ~/spark"
        fi
      shell: bash

    - name: Parametrize
      id: params
      run: |
        echo "artifact-id=$(grep --max-count=1 "<artifactId>.*</artifactId>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")" >> $GITHUB_OUTPUT
        echo "version=$(grep --max-count=1 "<version>.*</version>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")" >> $GITHUB_OUTPUT
        echo "graphframes-version=$(grep --max-count=1 "<graphframes.version>.*</graphframes.version>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")" >> $GITHUB_OUTPUT
        echo "home=$(cd ~; pwd)" >> $GITHUB_OUTPUT
      shell: bash

    - name: Prepare Integration Tests
      run: |
        mvn --batch-mode -Dspotless.check.skip -DskipTests install
        cd examples/scala
        mvn --batch-mode -Dspotless.check.skip package
      shell: bash

    - name: Start Dgraph cluster (Small)
      id: dgraph-small
      env:
        DGRAPH_TEST_CLUSTER_VERSION: ${{ inputs.dgraph-version }}
      run: |
        cp -v dgraph-instance.*.sh /tmp/
        echo "docker=$(/tmp/dgraph-instance.background.sh)" >> $GITHUB_OUTPUT
        sleep 10
        if [[ "${{ inputs.dgraph-version }}" != "20.03."* ]]
        then
          /tmp/dgraph-instance.drop-all.sh
        fi
        /tmp/dgraph-instance.schema.sh
        /tmp/dgraph-instance.insert.sh
      shell: bash

    - name: Integration Test (Example)
      env:
        SPARK_LOCAL_IP: 127.0.0.1
        SPARK_HOME: ${{ steps.params.outputs.home }}/spark
        ARTIFACT_ID: ${{ steps.params.outputs.artifact-id }}
        VERSION: ${{ steps.params.outputs.version }}
      run: |
        ${SPARK_HOME}/bin/spark-submit --repositories https://repo1.maven.org/maven2,https://repository.apache.org/content/repositories/releases,https://repository.apache.org/snapshots,https://repos.spark-packages.org --packages uk.co.gresearch.spark:${ARTIFACT_ID}:${VERSION},graphframes:graphframes:${{ steps.params.outputs.graphframes-version }}-s_${{ inputs.scala-compat-version }},org.scalactic:scalactic_${{ inputs.scala-compat-version }}:3.2.15 --class uk.co.gresearch.spark.dgraph.connector.example.ExampleApp examples/scala/target/spark-dgraph-connector-examples_*.jar
      shell: bash

    - name: Stop Dgraph cluster
      if: inputs.dgraph-version != '21.12.0'
      run: docker stop ${{ steps.dgraph-small.outputs.docker }}
      shell: bash

    - name: Start Dgraph cluster (Large)
      id: dgraph
      if: inputs.dgraph-version != '21.12.0'
      run: |
        if [[ "${{ inputs.dgraph-version }}" < "21.03.0" ]]
        then
          cache=""
          whitelist="--whitelist=0.0.0.0/0"
          maxUID="maxLeaseId"
        else
          cache="--cache size-mb=2048"
          whitelist="--security whitelist=0.0.0.0/0"
          maxUID="maxUID"
        fi

        mkdir dgraph
        curl -L -o dgraph/1million.rdf.gz "https://github.com/dgraph-io/tutorial/blob/master/resources/1million.rdf.gz?raw=true"
        docker run --rm -p 5080:5080 -p 6080:6080 -p 8080:8080 -p 9080:9080 -v $(pwd)/dgraph:/dgraph --name dgraph dgraph/dgraph:v${{ inputs.dgraph-version }} dgraph zero &
        sleep 2
        docker exec dgraph dgraph alpha $cache --zero localhost:5080 $whitelist &

        for attempt in {1..10}
        do
          sleep 10
          echo "attempt $attempt"
          if curl --data-binary @dgraph-instance.schema.live-loader.dql -H "Content-Type: text/plain;charset=UTF-8" http://localhost:8080/alter; then break; fi
          if [ $attempt -eq 10 ]; then exit 1; fi
        done

        docker exec dgraph dgraph live -f 1million.rdf.gz --alpha localhost:9080 --zero localhost:5080 -c 1
      shell: bash

    - name: Integration Test (Sparse)
      if: inputs.dgraph-version != '21.12.0'
      env:
        SPARK_LOCAL_IP: 127.0.0.1
        SPARK_HOME: ${{ steps.params.outputs.home }}/spark
        ARTIFACT_ID: ${{ steps.params.outputs.artifact-id }}
        VERSION: ${{ steps.params.outputs.version }}
      run: |
        ${SPARK_HOME}/bin/spark-submit --packages uk.co.gresearch.spark:${ARTIFACT_ID}:${VERSION},org.scalactic:scalactic_2.12:3.2.15 --class uk.co.gresearch.spark.dgraph.connector.example.SparseApp examples/scala/target/spark-dgraph-connector-examples_*.jar
      shell: bash

branding:
  icon: 'check-circle'
  color: 'green'
